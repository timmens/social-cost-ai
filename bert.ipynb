{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c510b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "396765c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unlist(l):\n",
    "    return list(itertools.chain.from_iterable(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43565e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b13dade",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Who is Aimee Van Wynsberghe ?\",\n",
    "    \"Aimee Van Wynsberghe is a Professor for Applied Ethics .\"\n",
    "]\n",
    "\n",
    "# Tokenized input with special tokens around it (for BERT: [CLS] at the beginning and [SEP] at the end)\n",
    "indexed_tokens = [tokenizer.encode(text, add_special_tokens=True) for text in sentences]\n",
    "\n",
    "segments_ids = [[k] * len(text) for k, text in enumerate(indexed_tokens)]\n",
    "segments_ids = unlist(segments_ids)\n",
    "\n",
    "indexed_tokens = unlist(indexed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "613422d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tim/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "model = torch.hub.load('huggingface/pytorch-transformers', 'model', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, token_type_ids=segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask a token that we will try to predict back with `BertForMaskedLM`\n",
    "\n",
    "masked_index = 8\n",
    "indexed_tokens[masked_index] = tokenizer.mask_token_id\n",
    "tokens_tensor = torch.tensor([indexed_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23013641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tim/.cache/torch/hub/huggingface_pytorch-transformers_master\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "masked_lm_model = torch.hub.load('huggingface/pytorch-transformers', 'modelForMaskedLM', 'bert-base-cased')\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = masked_lm_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "\n",
    "# Get the predicted token\n",
    "predicted_index = torch.argmax(predictions[0][0], dim=1)[masked_index].item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "assert predicted_token == 'Jim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfac77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3e458c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beb9c2ba",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196970aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answering_model = torch.hub.load('huggingface/pytorch-transformers', 'modelForQuestionAnswering', 'bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "question_answering_tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a40320b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(question, paragraph):\n",
    "    sentences = [paragraph, question]\n",
    "    \n",
    "    indexed_tokens = [\n",
    "        question_answering_tokenizer.encode(text, add_special_tokens=True)\n",
    "        for text in sentences\n",
    "    ]\n",
    "\n",
    "    segments_ids = [[k] * len(text) for k, text in enumerate(indexed_tokens)]\n",
    "    segments_ids = unlist(segments_ids)\n",
    "\n",
    "    indexed_tokens = unlist(indexed_tokens)\n",
    "    \n",
    "    segments_tensors = torch.tensor([segments_ids])\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "    # Predict the start and end positions logits\n",
    "    with torch.no_grad():\n",
    "        out = question_answering_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "\n",
    "    # get the highest prediction\n",
    "    answer = question_answering_tokenizer.decode(\n",
    "        indexed_tokens[torch.argmax(out.start_logits) : torch.argmax(out.end_logits) + 1]\n",
    "    )\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64ba1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"Aimee Van Wynsberghe is a Professor for Applied Ethics at the University of Bonn. \" \\\n",
    "            \"She moved to Bonn in the beginning of 2021.\" \\\n",
    "            \"There she launched the Sustainable AI Lab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "38270ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professor for applied ethics'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Who is Aimee Van Wynsberghe?\", paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b3c46376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'university of bonn'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"Where does Aimee Van Wynsberghe work?\", paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a171446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonn'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"In which city does Aimee Van Wynsberghe live?\", paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7de7788b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"When did Aimee move to bonn?\", paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3a77636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'applied ethics'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_question(\"\", paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4599a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82bdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48963e82",
   "metadata": {},
   "source": [
    "## Presentation\n",
    "\n",
    "0. Who am I and why am I here?\n",
    "    0.1. Who am I\n",
    "    0.2. Challenged by Aimee -- This is why I'm here\n",
    "1. Contents\n",
    "2. A primer on AI using NLP\n",
    "    2.1. AI -- Taking the magic out of it\n",
    "    2.2. NLP -- Why its useful and why its already in your pockets (smartphones)\n",
    "    2.3. Concepts BERT -- Specific models\n",
    "    2.4. Example -- Hands on programming\n",
    "3. The Project\n",
    "    3.1 Concepts\n",
    "    3.2 Current Status\n",
    "    3.3 Future\n",
    "4. Final Remarks\n",
    "    4.1 Questions\n",
    "    4.2 How to reach me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a4ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e4d694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ba730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad83de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98c591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d3578b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f24c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d9cc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcc3cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e062344d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbc7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03adb3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Aimee Van Wynsberghe is a Professor for Applied Ethics at the University of Bonn.\",\n",
    "    \"Who is Aimee Van Wynsberghe ?\",\n",
    "]\n",
    "\n",
    "indexed_tokens = [\n",
    "    question_answering_tokenizer.encode(text, add_special_tokens=True)\n",
    "    for text in sentences\n",
    "]\n",
    "\n",
    "segments_ids = [[k] * len(text) for k, text in enumerate(indexed_tokens)]\n",
    "segments_ids = unlist(segments_ids)\n",
    "\n",
    "indexed_tokens = unlist(indexed_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b65e8",
   "metadata": {},
   "source": [
    "The format is paragraph first and then question\n",
    "text_1 = \"Aimee van wynsberghe is a Professor for Applied Ethics of AI\"\n",
    "text_2 = \"Who was Jim Henson ?\"\n",
    "indexed_tokens = question_answering_tokenizer.encode(text_1, text_2, add_special_tokens=True)\n",
    "segments_ids = [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41ecfa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_tensors = torch.tensor([segments_ids])\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "# Predict the start and end positions logits\n",
    "with torch.no_grad():\n",
    "    out = question_answering_model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "\n",
    "# get the highest prediction\n",
    "answer = question_answering_tokenizer.decode(\n",
    "    indexed_tokens[torch.argmax(out.start_logits) : torch.argmax(out.end_logits) + 1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b401837e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'professor for applied ethics'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a534d788",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tim/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bed6b99a8784f79afb14ff8ab2c8cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/443 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00dfa59b4d44960bc7e0ed3dce0cd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/tim/.cache/torch/hub/huggingface_pytorch-transformers_master\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "908bcdd2e96d4f82a37b8da31e66d08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b10256415f847818bd66ed0fe05847d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e86f8bc5bf04dd099477264840e3328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assert answer == \"puppeteer\"\n",
    "\n",
    "# Or get the total loss which is the sum of the CrossEntropy loss for the start and end token positions (set model to train mode before if used for training)\n",
    "start_positions, end_positions = torch.tensor([12]), torch.tensor([14])\n",
    "multiple_choice_loss = question_answering_model(\n",
    "    tokens_tensor,\n",
    "    token_type_ids=segments_tensors,\n",
    "    start_positions=start_positions,\n",
    "    end_positions=end_positions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e708ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a6de21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6136102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66206d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8797378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58feb467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc7e87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
